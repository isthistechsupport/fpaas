{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import toml\n",
    "import imghdr\n",
    "from urllib.parse import urlsplit\n",
    "import requests\n",
    "\n",
    "try:\n",
    "    settings = toml.load(\"settings.toml\")\n",
    "except:\n",
    "    setup = toml.load(\"settings.template.toml\")\n",
    "    with open(\"settings.toml\", \"w\") as f:\n",
    "        f.write(toml.dumps(setup))\n",
    "        f.close()\n",
    "    print(\"Fill settings.toml and try again\")\n",
    "    quit(1)\n",
    "\n",
    "def file_as_bytes(file):\n",
    "    \"\"\"Opens a file as a string of bytes\"\"\"\n",
    "    with file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def save_file(url: str, file_path: str):\n",
    "    \"\"\"Downloads an URL to a file\"\"\"\n",
    "    resp = requests.get(url, stream=True, timeout=30)\n",
    "    assert resp.status_code == 200, f\"Response code was {resp.status_code}\"\n",
    "    #TODO: Add code to compare content-type header with file extension\n",
    "    with open(file_path, 'wb') as image_file:\n",
    "        for chunk in resp.iter_content():\n",
    "            image_file.write(chunk)\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def get_reddit_media(url: str, settings: dict):\n",
    "    \"\"\"Downloads media from Reddit\"\"\"\n",
    "    file_name = os.path.basename(urlsplit(url).path)\n",
    "    file_extension = os.path.splitext(url)[-1].lower()\n",
    "    # Fix for issue with i.reddituploads.com links not having a file extension in the URL\n",
    "    if not file_extension:\n",
    "        file_extension = '.jpg'\n",
    "        file_name += '.jpg'\n",
    "        url += '.jpg'\n",
    "    # Download the file\n",
    "    file_path = settings[\"media\"][\"media_folder\"] + '/' + file_name\n",
    "    print(f'[ OK ] Downloading file at URL {url} to {file_path}, file type identified as {file_extension}')\n",
    "    return save_file(url, file_path)\n",
    "\n",
    "\n",
    "def get_imgur_image_media(url: str, settings: dict):\n",
    "    \"\"\"Retrieves a single image from an Imgur i.imgur.com link\"\"\"\n",
    "    file_url = url.replace(\".gifv\", \".mp4\").lower()  # Get the file URL and replace GIFV or MP4 with GIF versions\n",
    "    file_name = os.path.basename(urlsplit(url).path)\n",
    "    print(f'[ OK ] Downloading Imgur media at URL {file_url} to {settings[\"media\"][\"media_folder\"]}')\n",
    "    file_path = save_file(file_url, f'{settings[\"media\"][\"media_folder\"]}/{file_name}')  # Saves the image\n",
    "    # Finally lets check if the imgur file is not a thumbnail\n",
    "    if \".jpg\" not in file_name and imghdr.what(file_path) != \"gif\":\n",
    "        print(\"[WARN] Imgur has not processed a GIF version of this link, so it can not be posted to Twitter\")\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "        except BaseException as e:\n",
    "            print(f'[EROR] Error while deleting media file: {str(e)}')\n",
    "        finally:\n",
    "            raise ValueError()\n",
    "    return file_path\n",
    "\n",
    "\n",
    "def get_imgur_endpoint(url: str, object: str, settings: dict):\n",
    "    \"\"\"Retrieves the info of any object/ID pair from the API\"\"\"\n",
    "    id = url.split('/')[-1].split('.')[0]  # Get the object ID = last element of the URL - file extension\n",
    "    response = requests.get(\n",
    "        f\"https://api.imgur.com/3/{object}/{id}\",\n",
    "        headers={'Authorization': f'Client-ID {settings[\"media\"][\"imgur_client\"]}'},\n",
    "        timeout=30\n",
    "    )\n",
    "    # Make sure we got a 200 response code\n",
    "    assert response.status_code == 200, f\"Response code for URL \\\"https://api.imgur.com/3/{object}/{id}\\\" was {response.status_code} with body {response.text}\"\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def get_imgur_image(url: str, settings: dict):\n",
    "    \"\"\"Retrieves any Imgur image\"\"\"\n",
    "    resp = get_imgur_endpoint(url, \"image\", settings)\n",
    "    # Call the image downloader on the image link\n",
    "    if \"image\" in resp[\"data\"][\"type\"]:\n",
    "        return get_imgur_image_media(resp[\"data\"][\"link\"], settings)\n",
    "\n",
    "\n",
    "def get_imgur_album(url: str, settings: dict):\n",
    "    \"\"\"Retrieves any Imgur album\"\"\"\n",
    "    resp = get_imgur_endpoint(url, \"album\", settings)\n",
    "    # Call the image downloader on the first image link of the album\n",
    "    if \"image\" in resp[\"data\"][\"images\"][0][\"type\"]:\n",
    "        return get_imgur_image_media(resp[\"data\"][\"images\"][0][\"link\"], settings)\n",
    "\n",
    "\n",
    "def get_imgur_gallery(url: str, settings: dict):\n",
    "    \"\"\"Retrieves any Imgur image or album within a gallery\"\"\"\n",
    "    resp = get_imgur_endpoint(url, \"gallery\", settings)\n",
    "    if \"image\" in resp[\"data\"][\"type\"]:\n",
    "        if resp[\"data\"][\"is_album\"]:\n",
    "            return get_imgur_album(url, settings)\n",
    "        else:\n",
    "            return get_imgur_image(url, settings)\n",
    "\n",
    "\n",
    "def get_imgur_media(url: str, settings: dict):\n",
    "    \"\"\"Downloads any Imgur link\"\"\"\n",
    "    assert settings[\"media\"][\"imgur_client\"] != \"\", \"Imgur client must not be empty\"\n",
    "    if \"/a/\" in url:  # It's an album\n",
    "        return get_imgur_album(url, settings)\n",
    "    elif \"/gallery/\" in url:  # It's a gallery\n",
    "        return get_imgur_gallery(url, settings)\n",
    "    else:  # It's a single image\n",
    "        return get_imgur_image(url, settings)\n",
    "\n",
    "def get_media(url):\n",
    "    try:\n",
    "        \"\"\"Retrieves static images and GIFs from popular image hosts\"\"\"\n",
    "        # Download and save the linked image\n",
    "        if 'redd.it' in url or 'reddituploads.com' in url:  # Reddit-hosted images\n",
    "            return get_reddit_media(url, settings)\n",
    "        elif 'imgur.com' in url:  # Imgur\n",
    "            return get_imgur_media(url, settings)\n",
    "        else:\n",
    "            pass\n",
    "    except BaseException as e:\n",
    "        print(f\"[WARN] Exception occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "#print(f\"Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=settings[\"reddit\"][\"id\"],\n",
    "    client_secret=settings[\"reddit\"][\"secret\"],\n",
    "    user_agent=\"python notebook/fpaas 0.1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_lazy = reddit.subreddit(settings[\"reddit\"][\"subreddits\"]).top(limit=None)\n",
    "\n",
    "posts = list(posts_lazy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "domains = Counter(list(map(lambda post: post.url.split(\"/\")[2], posts)))\n",
    "\n",
    "print(domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def user2str(user):\n",
    "    if user is None:\n",
    "        return \"[deleted]\"\n",
    "    else:\n",
    "        return user.name\n",
    "\n",
    "#helper function to dictionarize the submissions\n",
    "def sub2dict(sub):\n",
    "    return {\n",
    "        \"author\": user2str(sub.author),\n",
    "        \"created_utc\": sub.created_utc,\n",
    "        \"id\": sub.id,\n",
    "        \"name\": sub.name,\n",
    "        \"permalink\": sub.permalink,\n",
    "        \"score\": sub.score,\n",
    "        \"title\": sub.title,\n",
    "        \"upvote_ratio\": sub.upvote_ratio,\n",
    "        \"url\": sub.url\n",
    "    }\n",
    "\n",
    "j = len(posts)\n",
    "\n",
    "# Make sure media folder exists\n",
    "IMAGE_DIR = settings[\"media\"][\"media_folder\"]\n",
    "if not os.path.exists(IMAGE_DIR):\n",
    "    os.makedirs(IMAGE_DIR)\n",
    "    print('[ OK ] Media folder not found, created a new one')\n",
    "\n",
    "with open(f'dataset/metadata_{settings[\"reddit\"][\"subreddits\"]}.json', 'w') as f:\n",
    "    f.write(json.dumps(list(map(sub2dict, posts))))\n",
    "    f.close()\n",
    "\n",
    "for i, post in enumerate(posts, start=1):\n",
    "    print(f\"[ OK ] Checking post {i} out of {j}, {j-i} remaining\")\n",
    "    print(f\"[ OK ] Post URL is {post.url}\")\n",
    "    get_media(post.url)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6fd6c269a17798412f1639ffb40e43823bb2ad6af9310832b96ed47969990507"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
